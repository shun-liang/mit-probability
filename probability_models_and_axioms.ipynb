{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Probability Models and Axioms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilistic model is a quantitative description of a situation, a phenomenon, or an experiment.\n",
    "\n",
    "A probabilistic model involves two steps.\n",
    "\n",
    "- Sample Space: We need to describe the possible outcomes of an experiment.\n",
    "\n",
    "- Probability Laws: We need to specify how to assign probabilities to the outcomes or the collection of outcomes.\n",
    " - Axioms: Probabilities need to satisfy basic properties to be meaningful.\n",
    "   - e.g. Probabilities cannot be negative.\n",
    " - Properties that follow from the axioms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of probabilistic outcomes:\n",
    " - Discrete\n",
    " - Continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Space\n",
    "\n",
    "What ever an experiment is, like\n",
    " - flipping a coin\n",
    " - flipping a coin for 5 times\n",
    " - rolling a dice\n",
    " \n",
    "...There will be a set of possible outcomes of an experiment.\n",
    "\n",
    "We denote the set of possible outcomes of a experiment as $\\Omega$.\n",
    "\n",
    "The elements of a sample space should be\n",
    " - Mutually exclusive\n",
    "  - At the end of an experiment, there can only be one of the outcomes that has happened.\n",
    " - Collectively exhaustive\n",
    "  - Together, all the elements of the sample space exhaust all the possibilities.\n",
    " - At the \"right\" granularity\n",
    "  - The right granularity will include the sufficient but only relevant information in the model.\n",
    "  - For example, for flipping a coin, the weather of the location of the experiment will be irrelevant information\n",
    "    - Hence $\\Omega = \\{H, T\\}$ will be a better sample space compare to $\\Omega' = \\{H~and~rain, H~and~no~rain, T~and~rain, T~and~no~rain\\}$, although the elements in latter sample space are also mutually exclusive and collective exhaustive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Space Examples\n",
    "\n",
    "Samples space are sets. And a sample space can be finite, infinite, discrete, continuous, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: 2 rolls of a tetrahedral die\n",
    "\n",
    "One possible representation of the sample space is the following\n",
    "\n",
    "![](assets/sample_space_tetrahedral_die_xy.png)\n",
    "\n",
    "...and the order of the dice roll matters. E.g. $(2, 3)$ is a different outcome to $(3, 2)$.\n",
    "\n",
    "This is case of models that the probabilistic experiment can be described in phases or stages.\n",
    "\n",
    "It is useful to describe the such an experiment as a sequential description in terms of a tree.\n",
    "\n",
    "![](assets/sample_space_tetrahedral_die_tree.png)\n",
    "\n",
    "In both descriptions, we have $16$ possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Throwing a dart towards a target as a unit square\n",
    "\n",
    "And outcome will the dart hits point $(x, y)$ on the target such that $0 \\leq x, y \\leq 1$, while $x$ and $y$ are real numbers.\n",
    "\n",
    "![](assets/sample_space_dart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Axioms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition: Event\n",
    "\n",
    "Recall the dart example above. What is the probability of the dart hits on an exact point $(x, y)$ for any particular $x$ and $y$?\n",
    "\n",
    "The probability of such an outcome would be essentially $0$. And it is natural that in a continuous model that any individual point should have a $0$ probability.\n",
    "\n",
    "In this case instead of assigning probabilities to individual points, we will assign probabilities to a **subset** of the sample space.\n",
    "\n",
    "A subset of the sample space is called an **event**.\n",
    "\n",
    "The probability of an event $A$ is denoted as $P(A)$.\n",
    "\n",
    "Why is this called an event? Because at the end of the experiment, the outcome of the experiment is either in the subset $A$ (then we would say event $A$ has occurred), or is outside $A$ (then we would say event $A$ did not occurred).\n",
    "\n",
    "![](assets/continous_event.png)\n",
    "\n",
    "By convention, probabilities are always given between $0$ and $1$.\n",
    "\n",
    "Intuitively, $0$ probability means something practically cannot happen. And $1$ probability means practically the event of interest is going to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axioms\n",
    "\n",
    "The rules all probabilities should satisfy are call the Axioms of Probability.\n",
    "\n",
    "1. Non-negativity: $P(A) \\geq 0$ (a)\n",
    "2. Normalization: $P(\\Omega) = 1$ (b)\n",
    "3. (Finite) Additivity (to be strengthen later): If $A \\cap B = \\emptyset$, then $P(A \\cup B) = P(A) + P(B)$ (c)\n",
    "\n",
    "![](assets/additivity_axiom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Properties of Probabilities\n",
    "\n",
    "We know that $A \\cup A^C = \\Omega$ (d), and $A \\cap A^C = \\emptyset$ (e).\n",
    "\n",
    "We can derive some properties of probabilities from the Axioms of Probability.\n",
    "\n",
    "#### 1. $P(A) + P(A^C) = 1$\n",
    "\n",
    "##### Proof\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "1 &= P(\\Omega) & \\text{(from (b))}\\\\\n",
    "&= P(A \\cup A^C) & \\text{(from (d))} \\\\\n",
    "&= P(A) + P(A^C) & \\text{(from (c))}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "\n",
    "#### 2. $P(A) \\leq 1$\n",
    "\n",
    "##### Proof\n",
    "\n",
    "We know $P(A) + P(A^C) = 1$ from (1), and $P(A^C) \\geq 0$ (from (a)). Then we have\n",
    "\n",
    "$P(A) = 1 - P(A^C) \\leq 1$\n",
    "\n",
    "\n",
    "#### 3. $P(\\emptyset) = 0$\n",
    "\n",
    "##### Proof\n",
    "\n",
    "We know that $\\Omega^C = \\emptyset$.\n",
    "\n",
    "Hence $P(\\Omega) + P(\\emptyset) = P(\\Omega) + P(\\Omega^C) = 1$ (from 1).\n",
    "\n",
    "Hence\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(\\emptyset) &= 1 - P(\\Omega) \\\\\n",
    "&= 1 - 1 & \\text{(from b)}\\\\\n",
    "&= 0\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "\n",
    "#### 4. $P(A \\cup B \\cup C) = P(A) + P(B) + P(C)$, given $A, B, and~C$ are disjoint events. And similarly for $k$ disjoint events.\n",
    "\n",
    "##### Proof\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(A \\cup B \\cup C) &= P((A \\cup B) \\cup C) \\\\\n",
    "&= P(A \\cup B) + P(C) & \\text{from (c)} \\\\\n",
    "&= P(A) + P(B) + P(C) & \\text{from (c)}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "From this, we can easily generalize that $P(A_1 \\cup A_2 \\cup ... \\cup A_k) = \\sum_{i=1}^{k} P(A_k)$\n",
    "\n",
    "And because $\\{s_1, s_2, ..., s_k\\} = \\{s_1\\} \\cup \\{s_2\\} \\cup ... \\cup \\{s_k\\}$, we have\n",
    "\n",
    "#### $P(\\{s_1, s_2, ..., s_k\\}) = P(\\{s_1\\}) + P(\\{s_2\\}) + ... + P(\\{s_k\\}) = P(s_1) + P(s_2) + ... + P(s_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More properties of Probabilities\n",
    "\n",
    "#### 5. If $A \\subset B$, then $P(A) \\leq P(B)$.\n",
    "\n",
    "##### Proof\n",
    "\n",
    "We know\n",
    "\n",
    "$B = A \\cup (B \\cap A^C)$.\n",
    "\n",
    "Hence\n",
    "\n",
    "$P(B) = P(A) + P(B \\cap A^C)$.\n",
    "\n",
    "From (a) we know $P(B \\cap A^C) \\geq 0$.\n",
    "\n",
    "Hence $P(B) = P(A) + P(B \\cap A^C) \\geq P(A)$.\n",
    "\n",
    "#### 6. $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$. Note $A$ and $B$ are not necessarily disjoint here.\n",
    "\n",
    "##### Proof\n",
    "\n",
    "Let represent $A \\cup B$ in terms of disjoint events.\n",
    "\n",
    "Let $a = P(A \\cap B^C)$, $b = P(A \\cap B)$, and $c = P(B \\cap A^C)$.\n",
    "\n",
    "Hence\n",
    "\n",
    "$P(A \\cup B) = a + b + c$\n",
    "\n",
    "Then we have\n",
    "\n",
    "$P(A) + P(B) - P(A \\cap B) = (a + b) + (b + c) - b = a + b + c = P(A \\cup B)$.\n",
    "\n",
    "##### Union Bound\n",
    "\n",
    "Since $P(A \\cap B) \\geq 0$, we have $P(A) + P(B) \\geq P(A \\cup B)$.\n",
    "\n",
    "##### 7. $P(A \\cup B \\cup C) = P(A) + P(A^C \\cap B) + P(A^C \\cap B^C \\cap C)$. Note $A$, $B$ and $C$ are not necessarily disjoint here.\n",
    "\n",
    "##### Proof\n",
    "\n",
    "Let's represent $A \\cup B \\cup C$ as a union of disjoint sets\n",
    "\n",
    "$A \\cup B \\cup C = A \\cup (B \\cap A^C) \\cup (A^C \\cap B^C \\cap C)$.\n",
    "\n",
    "Hence $P(A \\cup B \\cup C) = P(A) + P(A^C \\cap B) + P(A^C \\cap B^C \\cap C)$ (from 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Discrete Example\n",
    "\n",
    "- Two rolls of a tetrahedral die (First roll's outcome denoted as $X$, second roll's outcome denoted as $Y$)\n",
    "- Let every possible outcome has probability $\\frac{1}{16}$\n",
    "\n",
    "![](assets/sample_space_tetrahedral_die_xy.png)\n",
    "\n",
    "$P(X = 1) = 4 \\cdot \\frac{1}{16} = \\frac{1}{4}$.\n",
    "\n",
    "Let $Z = min(X, Y)$.\n",
    "\n",
    "$P(Z = 4) = P(X = Y = 4) = \\frac{1}{16}$ as the event will be $\\{(4, 4)\\}$.\n",
    "\n",
    "$P(Z = 2) = \\frac{5}{16}$ as the event will be $\\{(2, 2), (2, 3), (2, 4), (3, 2), (4, 2)\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete Uniform Law\n",
    "\n",
    "- Assume $\\Omega$ consists of $n$ equally likely elements\n",
    "- Assume $A$ consists of $k$ elements\n",
    "\n",
    "![](assets/discrete_uniform_law.png)\n",
    "\n",
    "Then\n",
    "\n",
    "$P(A) = k \\cdot \\frac{1}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Continuous Example\n",
    "\n",
    "Revisiting the earlier dart throwing example.\n",
    "\n",
    "![](assets/sample_space_dart.png)\n",
    "\n",
    "Uniform probability law: Probability = Area.\n",
    "\n",
    "- $P(\\{(x, y)\\} | x + y \\leq \\frac{1}{2}) = \\frac{1}{2}(\\frac{1}{2} \\frac{1}{2}) = \\frac{1}{8}$.\n",
    "![](assets/continuous_uniform_law_ex1.png)\n",
    "\n",
    "- $P(\\{0.5, 0.3\\}) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability calculation steps\n",
    "\n",
    "- Specify the sample space\n",
    "- Specify a probability law\n",
    "- Identify an event of interest\n",
    "- Calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countable Additivity\n",
    "\n",
    "We carry out an experiment whose outcome is arbitrary large positive integer.\n",
    "\n",
    "For example, suppose we keep tossing a coin until we observe heads for the first time.\n",
    "\n",
    "- Sample space: $\\{1, 2, ...\\}$\n",
    "\n",
    "- Probability law: $P(n) = \\frac{1}{2^n}$, $n = 1, 2, ...$\n",
    " - Is that a good probability law? From the geometric series we know that $\\frac{1}{2} \\sum_{n=0}^{\\infty} \\frac{1}{2^n} = \\frac{1}{2} \\frac{1}{1 - \\frac{1}{2}} = 1$\n",
    " \n",
    "Let calculate the probability of another event of the same experiment.\n",
    "\n",
    "What is the probability that the outcome is even?\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(even) &= P(\\{2, 4, 6, ...\\}) \\\\\n",
    "&= P(2) + P(4) + P(6) + ... & \\text{from(4), which is based on (c) finite additivity} \\\\\n",
    "&= \\frac{1}{2^2} + \\frac{1}{2^4} + \\frac{1}{2^6} + ... \\text{(from the probability law of the experiment)}\\\\\n",
    "&= \\frac{1}{4}(1 + \\frac{1}{4} + \\frac{1}{4^2} + ...) \\\\\n",
    "&= \\frac{1}{4} (\\frac{1}{1 - \\frac{1}{4}}) & \\text{(from geometric series)} \\\\\n",
    "&= \\frac{1}{4} \\cdot \\frac{4}{3} \\\\\n",
    "&= \\frac{1}{3}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Is this correct? We have used the property (4) which is based on finite additivity, while the sum of probabilities here is infinite.\n",
    "\n",
    "The way out of this dilemma is to introduce an additional axiom that will indeed allow this kind of calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countable Additivity Axiom\n",
    "\n",
    "To strengthen the finite additivity axiom, we are introducing an axiom that\n",
    "\n",
    "If $A_1, A_2, A_3, ...$ is an infinite **sequence** of of __disjoint__ events, then\n",
    "\n",
    "$P(A_1 \\cup A_2 \\cup A_3 \\cup ...) = P(A_1) + P(A_2) + P(A_3) + ...$\n",
    "\n",
    "Note the mathematical subtleties of the term ***sequence** here.\n",
    "\n",
    "For example, for the unit square dart throwing experiment, does this axiom implies that\n",
    "\n",
    "$P(\\Omega) = P(\\cup \\{(x, y)\\}) = \\sum P(\\{(x, y)\\}) = \\sum 0 = 0$, which appears to be a paradox?\n",
    "\n",
    "No. $\\mathbb{R}$ is uncountable, hence the unit square is an uncountable set, hence we can not find a sequence of $\\{(x, y)\\}$ to traverse the sample space $\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Using countable additivity\n",
    "\n",
    "Let the sample space be the set of positive integers and suppose that $P(n) = \\frac{1}{2^n}$, for $n = 1, 2, ...$. Find the probability of set $\\{3, 6, 9, ...\\}$, that is, of the set of of positive integers that are multiples of $3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(multiples~of~3) &= P(\\{3, 6, 9, ..\\}) \\\\\n",
    "&= P(3) + P(6) + P(9) + ... & \\text{(from Countable Additivity Axiom)}\\\\\n",
    "&= \\frac{1}{2^3} + \\frac{1}{2^6} + \\frac{1}{2^9} + ... \\\\\n",
    "&= \\frac{1}{2^3} (1 + \\frac{1}{2^3} + (\\frac{1}{2^3})^2) + ...) \\\\\n",
    "&= \\frac{1}{2^3} (\\frac{1}{1 - \\frac{1}{2^3}}) & \\text{(from geometric series)}\\\\\n",
    "&= \\frac{1}{2^3} \\frac{2^3}{2^3 - 1} \\\\\n",
    "&= \\frac{1}{7}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Uses of Probabilities\n",
    "\n",
    "- A narrow point of view: Probability Theory is just a bunch of math\n",
    " - Axioms $\\implies$ Theorems\n",
    " \n",
    "- Are probabilities frequencies?\n",
    " - $P(coin~toss~head) = \\frac{1}{2}$\n",
    " - $P(the~president~of~...~will~be~re-elected) = 0.7$\n",
    " \n",
    "- Probabilities are often interpreted as\n",
    " - Description of beliefs\n",
    " - Betting preferences\n",
    " - Which are subjective\n",
    " \n",
    "### The role of probability theory\n",
    "- A framework for analyzing phenomena with uncertain outcomes\n",
    " - Rules of consistent reasoning\n",
    " - Used for predictions and decisions\n",
    " \n",
    "![](assets/probability_theory_big_picture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
